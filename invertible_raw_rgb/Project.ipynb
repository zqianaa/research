{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import rawpy\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import glob\n",
    "import os, time, scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get ids of training set\n",
    "input_dir = './dataset/HUAWEIMATE20/'\n",
    "train_fns = glob.glob(input_dir + 'a*.dng')\n",
    "train_ids = [int(os.path.basename(train_fn)[1:5]) for train_fn in train_fns]\n",
    "# Initialize crop size\n",
    "ps = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return tf.maximum(x * 0.2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    # black level of NIKON D70 is 128, and the raw image is in 12 bits.\n",
    "    im = np.maximum(im - 128, 0) / (4096 - 128) \n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
    "    pool_size = 2\n",
    "    deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
    "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
    "\n",
    "    deconv_output = tf.concat([deconv, x2], 3)\n",
    "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
    "\n",
    "    return deconv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(data):\n",
    "    print(\"1\")\n",
    "    conv1 = slim.conv2d(data, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv1_1')\n",
    "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv1_2')\n",
    "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
    "\n",
    "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv2_1')\n",
    "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv2_2')\n",
    "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
    "\n",
    "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv3_1')\n",
    "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv3_2')\n",
    "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
    "\n",
    "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv4_1')\n",
    "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv4_2')\n",
    "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
    "\n",
    "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=relu, scope='g_conv5_1')\n",
    "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=relu, scope='g_conv5_2')\n",
    "\n",
    "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
    "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv6_1')\n",
    "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv6_2')\n",
    "\n",
    "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
    "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv7_1')\n",
    "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv7_2')\n",
    "\n",
    "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
    "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv8_1')\n",
    "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv8_2')\n",
    "\n",
    "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
    "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv9_1')\n",
    "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv9_2')\n",
    "\n",
    "    conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
    "    out = tf.depth_to_space(conv10, 2)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.17549431\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.09846735\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.12337265\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.16338319\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.17046161\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.1599279\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.19059773\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.12339434\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.1409844\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.22422183\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.21742569\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.18269403\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.21149208\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.1990137\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.18621822\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.2366453\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.20843136\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.18582767\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.22626655\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.21012902\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.29333028\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.11997503\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.27244082\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.48433164\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.43111086\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.5011677\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.14050326\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.22127992\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.14451128\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.20697267\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.23242843\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.256304\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.23360823\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.15814684\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.14156212\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.20568763\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.21907015\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.16650504\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.20645876\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.14240901\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.11248797\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.120569386\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.09025121\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.17914212\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.13286234\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.0913625\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.11344537\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.099180676\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.09113508\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.087113954\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.12942904\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.17431927\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.13052155\n",
      "input_shape (1, 512, 512, 4)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.12609701\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9e0a923b265b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             _, G_current, output = sess.run([G_opt, G_loss, output_image],\n\u001b[0;32m---> 60\u001b[0;31m                                         feed_dict={input_image: input_patch, target_image: target_patch, lr: learning_rate})\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_patch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a session.\n",
    "sess = tf.Session()\n",
    "# Reserve memory in the flow for input and label.\n",
    "input_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
    "target_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
    "output_image = network(input_image)\n",
    "# Define the loss function.\n",
    "G_loss = tf.reduce_mean(tf.abs(output_image - target_image))\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "lr = tf.placeholder(tf.float32)\n",
    "# Define optimizer for the flow.\n",
    "G_opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss)\n",
    "\n",
    "input_images = [None] * len(train_ids)\n",
    "target_images = [None] * len(train_ids)\n",
    "learning_rate = 1e-4\n",
    "g_loss = np.zeros((5000, 1))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(4001):\n",
    "    if epoch > 2000:\n",
    "        learning_rate = 1e-5\n",
    "    for ind in np.random.permutation(len(train_ids)):\n",
    "        # get the path from image id\n",
    "        train_id = train_ids[ind]\n",
    "        in_files = glob.glob(input_dir + 'a%04d*.dng' % train_id)\n",
    "        in_path = in_files[0]\n",
    "        \n",
    "        if input_images[ind] is None:\n",
    "            raw = rawpy.imread(in_path)\n",
    "            input_images[ind] = np.expand_dims(pack_raw(raw), axis=0)\n",
    "\n",
    "            im = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            target_images[ind] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "\n",
    "        H = input_images[ind].shape[1]\n",
    "        W = input_images[ind].shape[2]\n",
    "        for z in range(10):\n",
    "            xx = np.random.randint(0, W - ps)\n",
    "            yy = np.random.randint(0, H - ps)\n",
    "\n",
    "            input_patch = input_images[ind][:, yy:yy + ps, xx:xx + ps, :]\n",
    "            target_patch = target_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]\n",
    "\n",
    "            if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
    "                input_patch = np.flip(input_patch, axis=1)\n",
    "                target_patch = np.flip(target_patch, axis=1)\n",
    "            if np.random.randint(2, size=1)[0] == 1:\n",
    "                input_patch = np.flip(input_patch, axis=2)\n",
    "                target_patch = np.flip(target_patch, axis=2)\n",
    "            if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
    "                input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
    "                target_patch = np.transpose(target_patch, (0, 2, 1, 3))\n",
    "            \n",
    "            input_patch = np.minimum(input_patch, 1.0)\n",
    "\n",
    "            _, G_current, output = sess.run([G_opt, G_loss, output_image],\n",
    "                                        feed_dict={input_image: input_patch, target_image: target_patch, lr: learning_rate})\n",
    "            output = np.minimum(np.maximum(output, 0), 1)\n",
    "            print('input_shape', input_patch.shape)\n",
    "            print('output_shape', output.shape)\n",
    "            #g_loss[ind] = G_current\n",
    "            print('loss', G_current)\n",
    "            #print(\"%d Loss=%.3f\" % (epoch, np.mean(g_loss[np.where(g_loss)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
