{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import rawpy\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import glob\n",
    "import os, time, scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get ids of training set\n",
    "input_dir = './dataset/HUAWEIMATE20/'\n",
    "#input_dir = './dataset/NIKOND70/'\n",
    "checkpoint_dir = './result/'\n",
    "result_dir = './result/'\n",
    "save_freq = 2\n",
    "train_fns = glob.glob(input_dir + 'a*.dng')\n",
    "train_ids = [int(os.path.basename(train_fn)[1:5]) for train_fn in train_fns]\n",
    "#train_ids = train_ids[0:5]\n",
    "# Initialize crop size\n",
    "ps = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return tf.maximum(x * 0.2, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "def pack_raw(raw):\n",
    "    # pack Bayer image to 4 channels\n",
    "    im = raw.raw_image_visible.astype(np.float32)\n",
    "    print(\"black_level: \", raw.black_level_per_channel)\n",
    "    # black level of NIKON D70 is 128, and the raw image is in 12 bits.\n",
    "    im = np.maximum(im, 0) / 4096\n",
    "    im = np.expand_dims(im, axis=2)\n",
    "    img_shape = im.shape\n",
    "    H = img_shape[0]\n",
    "    W = img_shape[1]\n",
    "\n",
    "    out = np.concatenate((im[0:H:2, 0:W:2, :],\n",
    "                          im[0:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 1:W:2, :],\n",
    "                          im[1:H:2, 0:W:2, :]), axis=2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample_and_concat(x1, x2, output_channels, in_channels):\n",
    "    pool_size = 2\n",
    "    deconv_filter = tf.Variable(tf.truncated_normal([pool_size, pool_size, output_channels, in_channels], stddev=0.02))\n",
    "    deconv = tf.nn.conv2d_transpose(x1, deconv_filter, tf.shape(x2), strides=[1, pool_size, pool_size, 1])\n",
    "\n",
    "    deconv_output = tf.concat([deconv, x2], 3)\n",
    "    deconv_output.set_shape([None, None, None, output_channels * 2])\n",
    "\n",
    "    return deconv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(data):\n",
    "    print(\"1\")\n",
    "    conv1 = slim.conv2d(data, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv1_1')\n",
    "    conv1 = slim.conv2d(conv1, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv1_2')\n",
    "    pool1 = slim.max_pool2d(conv1, [2, 2], padding='SAME')\n",
    "\n",
    "    conv2 = slim.conv2d(pool1, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv2_1')\n",
    "    conv2 = slim.conv2d(conv2, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv2_2')\n",
    "    pool2 = slim.max_pool2d(conv2, [2, 2], padding='SAME')\n",
    "\n",
    "    conv3 = slim.conv2d(pool2, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv3_1')\n",
    "    conv3 = slim.conv2d(conv3, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv3_2')\n",
    "    pool3 = slim.max_pool2d(conv3, [2, 2], padding='SAME')\n",
    "\n",
    "    conv4 = slim.conv2d(pool3, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv4_1')\n",
    "    conv4 = slim.conv2d(conv4, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv4_2')\n",
    "    pool4 = slim.max_pool2d(conv4, [2, 2], padding='SAME')\n",
    "\n",
    "    conv5 = slim.conv2d(pool4, 512, [3, 3], rate=1, activation_fn=relu, scope='g_conv5_1')\n",
    "    conv5 = slim.conv2d(conv5, 512, [3, 3], rate=1, activation_fn=relu, scope='g_conv5_2')\n",
    "\n",
    "    up6 = upsample_and_concat(conv5, conv4, 256, 512)\n",
    "    conv6 = slim.conv2d(up6, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv6_1')\n",
    "    conv6 = slim.conv2d(conv6, 256, [3, 3], rate=1, activation_fn=relu, scope='g_conv6_2')\n",
    "\n",
    "    up7 = upsample_and_concat(conv6, conv3, 128, 256)\n",
    "    conv7 = slim.conv2d(up7, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv7_1')\n",
    "    conv7 = slim.conv2d(conv7, 128, [3, 3], rate=1, activation_fn=relu, scope='g_conv7_2')\n",
    "\n",
    "    up8 = upsample_and_concat(conv7, conv2, 64, 128)\n",
    "    conv8 = slim.conv2d(up8, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv8_1')\n",
    "    conv8 = slim.conv2d(conv8, 64, [3, 3], rate=1, activation_fn=relu, scope='g_conv8_2')\n",
    "\n",
    "    up9 = upsample_and_concat(conv8, conv1, 32, 64)\n",
    "    conv9 = slim.conv2d(up9, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv9_1')\n",
    "    conv9 = slim.conv2d(conv9, 32, [3, 3], rate=1, activation_fn=relu, scope='g_conv9_2')\n",
    "\n",
    "    conv10 = slim.conv2d(conv9, 12, [1, 1], rate=1, activation_fn=None, scope='g_conv10')\n",
    "    out = tf.depth_to_space(conv10, 2)\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "loaded ./result/model.ckpt\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./result/model.ckpt\n",
      "black_level:  [0, 0, 0, 0]\n",
      "before precrocessing:  (1, 1488, 1984, 4)\n",
      "after precrocessing:  (1, 2976, 3968, 3)\n",
      "target_shape (1, 1024, 1024, 3)\n",
      "input_shape (1, 512, 512, 4)\n",
      "target_shape (1, 1024, 1024, 3)\n",
      "output_shape (1, 1024, 1024, 3)\n",
      "loss 0.053660274\n",
      "0 Loss=0.054\n",
      "[[[[ 48.793774    38.684822     0.15564202]\n",
      "   [ 48.793774    47.22568     46.396885  ]\n",
      "   [ 47.287937    51.548637    66.54864   ]\n",
      "   ...\n",
      "   [ 32.505836    37.031128    30.77821   ]\n",
      "   [ 45.287937    47.66926     41.400776  ]\n",
      "   [ 45.027237    45.494164    50.945526  ]]\n",
      "\n",
      "  [[ 39.233463    40.447468    43.346302  ]\n",
      "   [ 44.618675    48.12451     54.653694  ]\n",
      "   [ 40.42412     45.59922     56.4358    ]\n",
      "   ...\n",
      "   [ 33.41245     36.836575    28.92607   ]\n",
      "   [ 33.59533     38.77821     34.2607    ]\n",
      "   [ 33.89105     38.696495    39.55642   ]]\n",
      "\n",
      "  [[ 37.490273    44.408558    66.80933   ]\n",
      "   [ 47.268482    48.34241     62.55253   ]\n",
      "   [ 44.11284     44.828793    50.653694  ]\n",
      "   ...\n",
      "   [ 46.          39.844357    31.338522  ]\n",
      "   [ 43.657585    40.42412     31.190662  ]\n",
      "   [ 39.63424     41.33463     37.964977  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[135.41634    129.35408    122.24513   ]\n",
      "   [135.41634    131.6887     128.88326   ]\n",
      "   [131.3463     127.93774    126.48249   ]\n",
      "   ...\n",
      "   [118.252914   107.178986    93.84435   ]\n",
      "   [120.92218    111.71206     97.59144   ]\n",
      "   [125.55253    110.54475     97.87938   ]]\n",
      "\n",
      "  [[138.68481    131.3035     121.68871   ]\n",
      "   [137.6031     131.48248    122.9144    ]\n",
      "   [135.70427    131.72372    124.015564  ]\n",
      "   ...\n",
      "   [128.57198    113.252914   100.058365  ]\n",
      "   [124.83658    111.898834    97.29961   ]\n",
      "   [131.03113    117.87549    100.18288   ]]\n",
      "\n",
      "  [[135.07782    129.42412    124.08171   ]\n",
      "   [131.28015    127.968864   123.0856    ]\n",
      "   [129.89493    128.28015    125.24124   ]\n",
      "   ...\n",
      "   [131.70427    112.42802    101.66537   ]\n",
      "   [128.87547    112.03113     95.72373   ]\n",
      "   [123.58366    110.657585    94.618675  ]]]]\n",
      "[[[[ 8.317974   10.149504    9.8076105 ]\n",
      "   [ 3.649465    7.2780404   0.54335576]\n",
      "   [16.979296   12.274034   11.241683  ]\n",
      "   ...\n",
      "   [11.289396   11.15543     2.9524777 ]\n",
      "   [21.072626    3.6419513   2.8760695 ]\n",
      "   [10.30636     6.289679    1.9351143 ]]\n",
      "\n",
      "  [[ 0.         12.873348    9.669837  ]\n",
      "   [ 0.          3.89649     3.26516   ]\n",
      "   [ 7.5388546  23.290688   10.390934  ]\n",
      "   ...\n",
      "   [18.401691   15.84677    14.0829315 ]\n",
      "   [16.222578   13.306155    0.3669246 ]\n",
      "   [14.930371   13.029402    9.524764  ]]\n",
      "\n",
      "  [[ 9.441048   20.685122   19.044844  ]\n",
      "   [13.556874    7.4277616   7.540101  ]\n",
      "   [26.703156   23.27877    23.866451  ]\n",
      "   ...\n",
      "   [16.341705   18.798807    9.960708  ]\n",
      "   [25.177214    3.728517    6.650051  ]\n",
      "   [10.093255    9.711764    4.9221196 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 9.495881    0.11375925 14.294737  ]\n",
      "   [ 0.         47.37901    75.57143   ]\n",
      "   [51.003296    4.1074667  32.79037   ]\n",
      "   ...\n",
      "   [64.14452    42.926517   58.12748   ]\n",
      "   [55.482624   29.341202   30.521265  ]\n",
      "   [45.310932   20.119785   18.652937  ]]\n",
      "\n",
      "  [[11.694775   34.683308    4.172394  ]\n",
      "   [66.38406     0.         26.764494  ]\n",
      "   [25.111689   34.32996    27.885721  ]\n",
      "   ...\n",
      "   [30.035843   24.375383   30.050602  ]\n",
      "   [28.189386    0.         19.491928  ]\n",
      "   [ 0.         17.874401    6.4101434 ]]\n",
      "\n",
      "  [[20.024313    0.          6.4496064 ]\n",
      "   [11.205051   29.045609   55.79807   ]\n",
      "   [47.006805    0.         15.379929  ]\n",
      "   ...\n",
      "   [21.946543   26.185081   37.98931   ]\n",
      "   [28.41696    12.5526     23.320692  ]\n",
      "   [17.097553    9.387287    3.4971633 ]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:82: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black_level:  [0, 0, 0, 0]\n",
      "before precrocessing:  (1, 1488, 1984, 4)\n",
      "after precrocessing:  (1, 2976, 3968, 3)\n",
      "target_shape (1, 1024, 1024, 3)\n",
      "input_shape (1, 512, 512, 4)\n",
      "target_shape (1, 1024, 1024, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7388371d9e03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         _, G_current, output = sess.run([G_opt, G_loss, output_image],\n\u001b[0;32m---> 69\u001b[0;31m                                         feed_dict={input_image: input_patch, target_image: target_patch, lr: learning_rate})\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a session.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Reserve memory in the flow for input and label.\n",
    "input_image = tf.placeholder(tf.float32, [None, None, None, 4])\n",
    "target_image = tf.placeholder(tf.float32, [None, None, None, 3])\n",
    "output_image = network(input_image)\n",
    "# Define the loss function.\n",
    "G_loss = tf.reduce_mean(tf.abs(output_image - target_image)*255)\n",
    "\n",
    "t_vars = tf.trainable_variables()\n",
    "lr = tf.placeholder(tf.float32)\n",
    "# Define optimizer for the flow.\n",
    "G_opt = tf.train.AdamOptimizer(learning_rate=lr).minimize(G_loss)\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "if ckpt:\n",
    "    print('loaded ' + ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "input_images = [None] * len(train_ids)\n",
    "target_images = [None] * len(train_ids)\n",
    "learning_rate = 1e-4\n",
    "g_loss = np.zeros((5000, 1))\n",
    "\n",
    "\n",
    "for epoch in range(4001):\n",
    "    if epoch > 2000:\n",
    "        learning_rate = 1e-5\n",
    "    i = 0\n",
    "    for ind in np.random.permutation(len(train_ids)):\n",
    "        if i == 5:\n",
    "            break\n",
    "        # get the path from image id\n",
    "        train_id = train_ids[ind]\n",
    "        in_files = glob.glob(input_dir + 'a%04d*.dng' % train_id)\n",
    "        in_path = in_files[0]\n",
    "        \n",
    "        if input_images[ind] is None:\n",
    "            raw = rawpy.imread(in_path)\n",
    "            input_images[ind] = np.expand_dims(pack_raw(raw), axis=0)\n",
    "            print(\"before precrocessing: \", input_images[ind].shape)\n",
    "            im = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "            target_images[ind] = np.expand_dims(np.float32(im / 65535.0), axis=0)\n",
    "            print(\"after precrocessing: \", target_images[ind].shape)\n",
    "\n",
    "        H = input_images[ind].shape[1]\n",
    "        W = input_images[ind].shape[2]\n",
    "        xx = np.random.randint(0, W - ps)\n",
    "        yy = np.random.randint(0, H - ps)\n",
    "\n",
    "        input_patch = input_images[ind][:, yy:yy + ps, xx:xx + ps, :]\n",
    "        target_patch = target_images[ind][:, yy * 2:yy * 2 + ps * 2, xx * 2:xx * 2 + ps * 2, :]\n",
    "        print('target_shape', target_patch.shape)\n",
    "\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random flip\n",
    "            input_patch = np.flip(input_patch, axis=1)\n",
    "            target_patch = np.flip(target_patch, axis=1)\n",
    "        if np.random.randint(2, size=1)[0] == 1:\n",
    "            input_patch = np.flip(input_patch, axis=2)\n",
    "            target_patch = np.flip(target_patch, axis=2)\n",
    "        if np.random.randint(2, size=1)[0] == 1:  # random transpose\n",
    "            input_patch = np.transpose(input_patch, (0, 2, 1, 3))\n",
    "            target_patch = np.transpose(target_patch, (0, 2, 1, 3))\n",
    "            \n",
    "        input_patch = np.minimum(input_patch, 1.0)\n",
    "        print('input_shape', input_patch.shape)\n",
    "        print('target_shape', target_patch.shape)\n",
    "            \n",
    "        _, G_current, output = sess.run([G_opt, G_loss, output_image],\n",
    "                                        feed_dict={input_image: input_patch, target_image: target_patch, lr: learning_rate})\n",
    "        output = np.minimum(np.maximum(output, 0), 1)\n",
    "        \n",
    "        print('output_shape', output.shape)\n",
    "        g_loss[ind] = G_current\n",
    "        print('loss', G_current)\n",
    "        print(\"%d Loss=%.3f\" % (epoch, np.mean(g_loss[np.where(g_loss)])))\n",
    "        if epoch % save_freq == 0:\n",
    "            if not os.path.isdir(result_dir + '%04d' % epoch):\n",
    "                os.makedirs(result_dir + '%04d' % epoch)\n",
    "            print(target_patch*255)\n",
    "            print(output*255)\n",
    "            temp = np.concatenate((target_patch[0, :, :, :], output[0, :, :, :]), axis=1)\n",
    "            scipy.misc.toimage(temp * 255, high=255, low=0, cmin=0, cmax=255).save(\n",
    "                result_dir + '%04d/%05d_00_train.jpg' % (epoch, train_id))\n",
    "        i += 1\n",
    "    saver.save(sess, checkpoint_dir + 'model.ckpt')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
